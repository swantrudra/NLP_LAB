{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aYL-LwdHyzde",
        "outputId": "1ef98593-e436-4235-92a9-d8ccb435dd20"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data] Downloading package omw-1.4 to /root/nltk_data...\n"
          ]
        }
      ],
      "source": [
        "import nltk\n",
        "import re\n",
        "import pandas as pd\n",
        "\n",
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')\n",
        "nltk.download('wordnet')\n",
        "nltk.download('omw-1.4')\n",
        "\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.preprocessing import LabelEncoder\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data = {\n",
        "    \"text\": [\n",
        "        \"I love Natural Language Processing!\",\n",
        "        \"Machine learning is AMAZING!!!\",\n",
        "        \"NLP helps computers understand human language\",\n",
        "        \"I love AI and Machine Learning\"\n",
        "    ],\n",
        "    \"label\": [\"positive\", \"positive\", \"neutral\", \"positive\"]\n",
        "}\n",
        "\n",
        "df = pd.DataFrame(data)\n",
        "print(df)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p7gKpA21y8J9",
        "outputId": "609855dd-98a8-4148-aae7-89f43bb2e874"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                                            text     label\n",
            "0            I love Natural Language Processing!  positive\n",
            "1                 Machine learning is AMAZING!!!  positive\n",
            "2  NLP helps computers understand human language   neutral\n",
            "3                 I love AI and Machine Learning  positive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def clean_text(text):\n",
        "    text = text.lower()\n",
        "    text = re.sub(r'[^a-z\\s]', '', text)\n",
        "    return text\n",
        "\n",
        "df[\"cleaned_text\"] = df[\"text\"].apply(clean_text)\n",
        "print(df[\"cleaned_text\"])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wZnuuLhFzEcW",
        "outputId": "246f2420-5b35-4b7e-d156-a0c1a459aa3d"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0               i love natural language processing\n",
            "1                      machine learning is amazing\n",
            "2    nlp helps computers understand human language\n",
            "3                   i love ai and machine learning\n",
            "Name: cleaned_text, dtype: object\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download('punkt_tab')\n",
        "\n",
        "stop_words = set(stopwords.words('english'))\n",
        "lemmatizer = WordNetLemmatizer()\n",
        "\n",
        "def preprocess_text(text):\n",
        "    tokens = word_tokenize(text)\n",
        "    tokens = [word for word in tokens if word not in stop_words]\n",
        "    tokens = [lemmatizer.lemmatize(word) for word in tokens]\n",
        "    return \" \".join(tokens)\n",
        "\n",
        "df[\"processed_text\"] = df[\"cleaned_text\"].apply(preprocess_text)\n",
        "print(df[\"processed_text\"])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ssWwC9xxzLu0",
        "outputId": "546c50ab-86f9-4778-c299-0fcfe1ce2b63"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt_tab.zip.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0               love natural language processing\n",
            "1                       machine learning amazing\n",
            "2    nlp help computer understand human language\n",
            "3                       love ai machine learning\n",
            "Name: processed_text, dtype: object\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "label_encoder = LabelEncoder()\n",
        "df[\"label_encoded\"] = label_encoder.fit_transform(df[\"label\"])\n",
        "\n",
        "print(df[[\"label\", \"label_encoded\"]])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JedWrFLFzZsF",
        "outputId": "c1b9c0ee-bf6e-4353-ea57-e7faa2fe756d"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "      label  label_encoded\n",
            "0  positive              1\n",
            "1  positive              1\n",
            "2   neutral              0\n",
            "3  positive              1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tfidf = TfidfVectorizer()\n",
        "tfidf_matrix = tfidf.fit_transform(df[\"processed_text\"])\n",
        "\n",
        "tfidf_df = pd.DataFrame(\n",
        "    tfidf_matrix.toarray(),\n",
        "    columns=tfidf.get_feature_names_out()\n",
        ")\n",
        "\n",
        "print(tfidf_df)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8tQjbOrzzcF0",
        "outputId": "0c7a875b-7100-4844-e033-c51819060496"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "         ai   amazing  computer      help     human  language  learning  \\\n",
            "0  0.000000  0.000000  0.000000  0.000000  0.000000  0.437791  0.000000   \n",
            "1  0.000000  0.667679  0.000000  0.000000  0.000000  0.000000  0.526405   \n",
            "2  0.000000  0.000000  0.421765  0.421765  0.421765  0.332524  0.000000   \n",
            "3  0.590819  0.000000  0.000000  0.000000  0.000000  0.000000  0.465809   \n",
            "\n",
            "       love   machine   natural       nlp  processing  understand  \n",
            "0  0.437791  0.000000  0.555283  0.000000    0.555283    0.000000  \n",
            "1  0.000000  0.526405  0.000000  0.000000    0.000000    0.000000  \n",
            "2  0.000000  0.000000  0.000000  0.421765    0.000000    0.421765  \n",
            "3  0.465809  0.465809  0.000000  0.000000    0.000000    0.000000  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.to_csv(\"cleaned_text_data.csv\", index=False)\n"
      ],
      "metadata": {
        "id": "bjBWf4BfzmiS"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tfidf_df.to_csv(\"tfidf_features.csv\", index=False)\n"
      ],
      "metadata": {
        "id": "LabYOXyozsBv"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "label_mapping = pd.DataFrame({\n",
        "    \"Label\": label_encoder.classes_,\n",
        "    \"Encoded_Value\": range(len(label_encoder.classes_))\n",
        "})\n",
        "\n",
        "label_mapping.to_csv(\"label_encoding_mapping.csv\", index=False)\n"
      ],
      "metadata": {
        "id": "tovmIREAzvNQ"
      },
      "execution_count": 11,
      "outputs": []
    }
  ]
}