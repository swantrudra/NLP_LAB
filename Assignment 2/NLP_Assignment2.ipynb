{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dQKyI10qwGLO",
        "outputId": "b76f3b76-9182-457e-faea-735b83d53d15"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting gensim\n",
            "  Downloading gensim-4.4.0-cp312-cp312-manylinux_2_24_x86_64.manylinux_2_28_x86_64.whl.metadata (8.4 kB)\n",
            "Requirement already satisfied: numpy>=1.18.5 in /usr/local/lib/python3.12/dist-packages (from gensim) (2.0.2)\n",
            "Requirement already satisfied: scipy>=1.7.0 in /usr/local/lib/python3.12/dist-packages (from gensim) (1.16.3)\n",
            "Requirement already satisfied: smart_open>=1.8.1 in /usr/local/lib/python3.12/dist-packages (from gensim) (7.5.0)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.12/dist-packages (from smart_open>=1.8.1->gensim) (2.0.1)\n",
            "Downloading gensim-4.4.0-cp312-cp312-manylinux_2_24_x86_64.manylinux_2_28_x86_64.whl (27.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m27.9/27.9 MB\u001b[0m \u001b[31m98.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: gensim\n",
            "Successfully installed gensim-4.4.0\n"
          ]
        }
      ],
      "source": [
        "import nltk\n",
        "nltk.download('punkt')\n",
        "\n",
        "from nltk.tokenize import word_tokenize\n",
        "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
        "!pip install gensim\n",
        "from gensim.models import Word2Vec\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "documents = [\n",
        "    \"I love natural language processing\",\n",
        "    \"Natural language processing is amazing\",\n",
        "    \"I love machine learning\",\n",
        "    \"Machine learning and NLP are related\"\n",
        "]\n"
      ],
      "metadata": {
        "id": "eAm8lvj4w2c5"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "count_vectorizer = CountVectorizer()\n",
        "bow_count = count_vectorizer.fit_transform(documents)\n",
        "\n",
        "print(\"Vocabulary:\")\n",
        "print(count_vectorizer.get_feature_names_out())\n",
        "\n",
        "print(\"\\nCount Occurrence Matrix:\")\n",
        "print(bow_count.toarray())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SR3jnNRbw9wR",
        "outputId": "5e7b590f-eb43-49fe-b56d-4effb00ed34d"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Vocabulary:\n",
            "['amazing' 'and' 'are' 'is' 'language' 'learning' 'love' 'machine'\n",
            " 'natural' 'nlp' 'processing' 'related']\n",
            "\n",
            "Count Occurrence Matrix:\n",
            "[[0 0 0 0 1 0 1 0 1 0 1 0]\n",
            " [1 0 0 1 1 0 0 0 1 0 1 0]\n",
            " [0 0 0 0 0 1 1 1 0 0 0 0]\n",
            " [0 1 1 0 0 1 0 1 0 1 0 1]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tfidf_vectorizer = TfidfVectorizer(norm='l2')\n",
        "bow_normalized = tfidf_vectorizer.fit_transform(documents)\n",
        "\n",
        "print(\"\\nNormalized Count Matrix (TF-IDF):\")\n",
        "print(bow_normalized.toarray())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GZeyrWzNxIwh",
        "outputId": "1e985a49-aed8-4bb6-ffb1-8fab8d7405a3"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Normalized Count Matrix (TF-IDF):\n",
            "[[0.         0.         0.         0.         0.5        0.\n",
            "  0.5        0.         0.5        0.         0.5        0.        ]\n",
            " [0.50867187 0.         0.         0.50867187 0.40104275 0.\n",
            "  0.         0.         0.40104275 0.         0.40104275 0.        ]\n",
            " [0.         0.         0.         0.         0.         0.57735027\n",
            "  0.57735027 0.57735027 0.         0.         0.         0.        ]\n",
            " [0.         0.43671931 0.43671931 0.         0.         0.34431452\n",
            "  0.         0.34431452 0.         0.43671931 0.         0.43671931]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tfidf_vectorizer = TfidfVectorizer()\n",
        "tfidf_matrix = tfidf_vectorizer.fit_transform(documents)\n",
        "\n",
        "print(\"TF-IDF Vocabulary:\")\n",
        "print(tfidf_vectorizer.get_feature_names_out())\n",
        "\n",
        "print(\"\\nTF-IDF Matrix:\")\n",
        "print(tfidf_matrix.toarray())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rgt3b4xsxS9L",
        "outputId": "4a8ea2a5-09fe-48a1-f3e1-1e05c78002a1"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "TF-IDF Vocabulary:\n",
            "['amazing' 'and' 'are' 'is' 'language' 'learning' 'love' 'machine'\n",
            " 'natural' 'nlp' 'processing' 'related']\n",
            "\n",
            "TF-IDF Matrix:\n",
            "[[0.         0.         0.         0.         0.5        0.\n",
            "  0.5        0.         0.5        0.         0.5        0.        ]\n",
            " [0.50867187 0.         0.         0.50867187 0.40104275 0.\n",
            "  0.         0.         0.40104275 0.         0.40104275 0.        ]\n",
            " [0.         0.         0.         0.         0.         0.57735027\n",
            "  0.57735027 0.57735027 0.         0.         0.         0.        ]\n",
            " [0.         0.43671931 0.43671931 0.         0.         0.34431452\n",
            "  0.         0.34431452 0.         0.43671931 0.         0.43671931]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download('punkt_tab') # Download the missing resource\n",
        "tokenized_docs = [word_tokenize(doc.lower()) for doc in documents]\n",
        "print(tokenized_docs)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u0FY6Vaxxnjx",
        "outputId": "988f3fa7-dd97-43a9-e1fc-e4d82653c276"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[['i', 'love', 'natural', 'language', 'processing'], ['natural', 'language', 'processing', 'is', 'amazing'], ['i', 'love', 'machine', 'learning'], ['machine', 'learning', 'and', 'nlp', 'are', 'related']]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data]   Unzipping tokenizers/punkt_tab.zip.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "w2v_model = Word2Vec(\n",
        "    sentences=tokenized_docs,\n",
        "    vector_size=100,\n",
        "    window=5,\n",
        "    min_count=1,\n",
        "    workers=4\n",
        ")\n"
      ],
      "metadata": {
        "id": "dmV_48-bxvqO"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vector_nlp = w2v_model.wv['nlp']\n",
        "print(\"Embedding for word 'nlp':\")\n",
        "print(vector_nlp)\n",
        "print(\"Vector size:\", len(vector_nlp))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EE18eYstx1NE",
        "outputId": "37201770-703b-482f-82c9-d34fd6e5d438"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Embedding for word 'nlp':\n",
            "[-0.00516529 -0.00666611 -0.00777445  0.00832348 -0.0019855  -0.00686369\n",
            " -0.00414805  0.00514986 -0.00288222 -0.00375776  0.00163125 -0.00278467\n",
            " -0.00157543  0.00106845 -0.0029711   0.00852681  0.00391159 -0.00997239\n",
            "  0.00625557 -0.00677056  0.00076876  0.00441551 -0.00509217 -0.00211932\n",
            "  0.00809817 -0.0042443  -0.00764569  0.00925809 -0.0021554  -0.0047261\n",
            "  0.00858085  0.00428055  0.00433615  0.00929944 -0.00845911  0.00526827\n",
            "  0.00204263  0.0041959   0.00169704  0.00445951  0.0044902   0.00611132\n",
            " -0.00320902 -0.00457812 -0.00042772  0.0025304  -0.00326847  0.00606732\n",
            "  0.00415291  0.0077703   0.00256765  0.00812078 -0.00138923  0.00808172\n",
            "  0.00372094 -0.00805493 -0.00393644 -0.00247479  0.00490311 -0.00087734\n",
            " -0.00283884  0.00783519  0.00934181 -0.00161813 -0.00517465 -0.00470158\n",
            " -0.00485904 -0.00960407  0.00136252 -0.00423184  0.00252485  0.00562758\n",
            " -0.00406335 -0.00959374  0.00154251 -0.00670499  0.00249388 -0.00379233\n",
            "  0.00707454  0.00063953  0.0035651  -0.00274376 -0.00170441  0.00766341\n",
            "  0.00140972 -0.00585557 -0.00784079  0.00123206  0.00646224  0.00556737\n",
            " -0.00898397  0.00860182  0.00404783  0.00747804  0.00976601 -0.00728802\n",
            " -0.00904391  0.00583919  0.00940647  0.00350019]\n",
            "Vector size: 100\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Words similar to 'language':\")\n",
        "print(w2v_model.wv.most_similar('language'))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CL6JZkdgx5aB",
        "outputId": "65cccffd-8224-40f7-9f31-fa1df20c2d22"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Words similar to 'language':\n",
            "[('love', 0.13158591091632843), ('are', 0.07523085176944733), ('machine', 0.06794975697994232), ('i', 0.04181476682424545), ('amazing', 0.04126745089888573), ('and', 0.013051219284534454), ('is', -0.009268556721508503), ('processing', -0.013450139202177525), ('related', -0.013759840279817581), ('natural', -0.044627055525779724)]\n"
          ]
        }
      ]
    }
  ]
}